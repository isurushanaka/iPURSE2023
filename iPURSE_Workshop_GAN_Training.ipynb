{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isurushanaka/iPURSE2023/blob/main/iPURSE_Workshop_GAN_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image-to-image translation with a conditional GAN**"
      ],
      "metadata": {
        "id": "fWJbNu8gN8w8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Dataset](https://github.com/isurushanaka/N2D250K)\n",
        "\n",
        "\n",
        "*   Night-to-day image translation\n",
        "*   Paired images\n",
        "\n",
        "<img src=\"https://github.com/isurushanaka/N2D250K/blob/main/Sample%20Images/paired_dataset-v.png?raw=true\"  width=\"22%\" height=\"70%\">\n",
        "\n"
      ],
      "metadata": {
        "id": "l3Py0iR9ZSdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN Implementation\n",
        "\n",
        "\n",
        "1.   Generator\n",
        "2.   Discriminator\n",
        "3.   Training Function\n",
        "4.   Data Loader\n",
        "5.   Helper Functions\n",
        "6.   Hyperparameters\n",
        "7.   Training\n",
        "\n"
      ],
      "metadata": {
        "id": "D5fKRR30YzTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Generator\n",
        "\n",
        "![](https://www.researchgate.net/profile/Chenxing-Wang/publication/349487608/figure/fig4/AS:1017165721378817@1619522614571/The-network-structure-of-pix2pix-including-the-structure-of-U-Net.png)"
      ],
      "metadata": {
        "id": "dZUTGu74loPw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En19DX0KYmCx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class genBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(genBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\") if down else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(nn.Conv2d(in_channels, 64, 4, 2, 1, padding_mode=\"reflect\"), nn.LeakyReLU(0.2),)\n",
        "        self.down1 = genBlock(64, 128, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = genBlock(128, 256, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down3 = genBlock(256, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down4 = genBlock(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down5 = genBlock(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down6 = genBlock(512, 512, down=True, act=\"leaky\", use_dropout=False)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU())\n",
        "\n",
        "        self.up1 = genBlock(512, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = genBlock(512 * 2, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up3 = genBlock(512 * 2, 512, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up4 = genBlock(512 * 2, 512, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up5 = genBlock(512 * 2, 256, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up6 = genBlock(256 * 2, 128, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up7 = genBlock(128 * 2, 64, down=False, act=\"relu\", use_dropout=False)\n",
        "\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        return self.final_up(torch.cat([up7, d1], 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Discriminator\n",
        "\n",
        "![](https://www.researchgate.net/profile/Chenxing-Wang/publication/349487608/figure/fig4/AS:1017165721378817@1619522614571/The-network-structure-of-pix2pix-including-the-structure-of-U-Net.png)"
      ],
      "metadata": {
        "id": "MGAvpQWxnok2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class discBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super(discBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels * 2,features[0],kernel_size=4,stride=2,padding=1,padding_mode=\"reflect\",),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(discBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),)\n",
        "            in_channels = feature\n",
        "\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"),)\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = torch.cat([x, y], dim=1)\n",
        "        x = self.initial(x)\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uOss3MzLnk3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training Function"
      ],
      "metadata": {
        "id": "hCOpSevd3am1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision.utils import save_image,make_grid\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "L1_LAMBDA = 10\n",
        "\n",
        "def train_fn(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler, writer, writer_step):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (night, day) in enumerate(loop):\n",
        "        night = night.to(DEVICE)\n",
        "        day = day.to(DEVICE)\n",
        "\n",
        "        # Train Discriminator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            day_fake = gen(night)\n",
        "            D_real = disc(night, day)\n",
        "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "            D_fake = disc(night, day_fake.detach())\n",
        "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "\n",
        "        disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_fake = disc(night, day_fake)\n",
        "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "            L1 = l1_loss(day_fake, day) * L1_LAMBDA\n",
        "            G_loss = G_fake_loss + L1\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        #training log\n",
        "        log_dict={\n",
        "            \"Disc_loss\":f\"{D_loss.mean().item()}\",\n",
        "            \"Gen_loss\":f\"{G_loss.mean().item()}\",\n",
        "\n",
        "            \"d_real\":f\"{torch.sigmoid(D_real).mean().item()}\",\n",
        "            \"d_fake\":f\"{torch.sigmoid(D_fake).mean().item()}\",\n",
        "\n",
        "        }\n",
        "        writer.add_scalar(\"Disc_loss\", float(log_dict[\"Disc_loss\"]), global_step=writer_step)\n",
        "        writer.add_scalar(\"Gen_loss\", float(log_dict[\"Gen_loss\"]), global_step=writer_step)\n",
        "        writer.add_scalar(\"d_real\", float(log_dict[\"d_real\"]), global_step=writer_step)\n",
        "        writer.add_scalar(\"d_fake\", float(log_dict[\"d_fake\"]), global_step=writer_step)\n",
        "\n",
        "        day_fake = day_fake * 0.5 + 0.5  # remove normalization#\n",
        "        img_grid = make_grid(day_fake)\n",
        "        writer.add_image('fake_day', img_grid, global_step=writer_step)\n",
        "\n",
        "        writer_step+=1\n",
        "\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            loop.set_postfix(D_real=torch.sigmoid(D_real).mean().item(),D_fake=torch.sigmoid(D_fake).mean().item(),)\n",
        "\n",
        "    return log_dict"
      ],
      "metadata": {
        "id": "iNhywy7N3ZdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Loader"
      ],
      "metadata": {
        "id": "mwS_wprttcSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},)\n",
        "\n",
        "\n",
        "class LoadDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.list_files = os.listdir(self.root_dir+\"/night_images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_files)\n",
        "\n",
        "    def get_images(self,index):\n",
        "        img_file = self.list_files[index]\n",
        "        try:\n",
        "            day_img_path = os.path.join(self.root_dir+\"/day_images\", img_file)\n",
        "            ngt_img_path = os.path.join(self.root_dir+\"/night_images\", img_file)\n",
        "            input_image = np.array(Image.open(ngt_img_path))\n",
        "            target_image = np.array(Image.open(day_img_path))\n",
        "\n",
        "            augmentations = transform(image=input_image, image0=target_image)\n",
        "            input_image = augmentations[\"image\"]\n",
        "            target_image = augmentations[\"image0\"]\n",
        "\n",
        "            return input_image, target_image\n",
        "        except Exception as e:\n",
        "            return self.get_images(index+1)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_image, target_image = self.get_images(index)\n",
        "        return input_image, target_image"
      ],
      "metadata": {
        "id": "rw3j2XQxtgiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Helper Functions"
      ],
      "metadata": {
        "id": "t3p_vZB7Uj0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.utils import save_image,make_grid\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "def val_fn(gen, validation_loader, epoch, saved_imgs_folder, writer):\n",
        "    x, y = next(iter(validation_loader))\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "        y_fake = gen(x)\n",
        "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
        "        save_image(y_fake, saved_imgs_folder + f\"/y_gen_{epoch}.png\")\n",
        "        save_image(x * 0.5 + 0.5, saved_imgs_folder + f\"/input_{epoch}.png\")\n",
        "\n",
        "        # create grid of images\n",
        "        img_grid = make_grid(y_fake)\n",
        "        writer.add_image('fake_day', img_grid, global_step=epoch)\n",
        "        if epoch == 1:\n",
        "            save_image(y * 0.5 + 0.5, saved_imgs_folder + f\"/label_{epoch}.png\")\n",
        "    gen.train()"
      ],
      "metadata": {
        "id": "vkhlgE8BUoty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Hyperparameters"
      ],
      "metadata": {
        "id": "nyKIsiTkU-CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_folder_path = \"/content/drive/MyDrive/iPURSE/Dataset/train\"\n",
        "validation_data_folder_path = \"/content/drive/MyDrive/iPURSE/Dataset/validation\"\n",
        "CHECKPOINT_DISC_PATH = \"/content/drive/MyDrive/iPURSE/Checkpoint/disc.pth.tar\"\n",
        "CHECKPOINT_GEN_PATH = \"/content/drive/MyDrive/iPURSE/Checkpoint/gen.pth.tar\"\n",
        "\n",
        "saved_imgs_folder_path = \"/content/drive/MyDrive/iPURSE/Saved_Images\"\n",
        "runs_path = \"/content/drive/MyDrive/iPURSE/runs\"\n",
        "\n",
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 16\n",
        "NUM_EPOCHS = 300\n",
        "\n",
        "\n",
        "LOAD_MODEL = True\n",
        "SAVE_MODEL = True"
      ],
      "metadata": {
        "id": "9VGsug6iTiVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Training"
      ],
      "metadata": {
        "id": "Qr30uyI1XOUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "CXHlIUEGpGoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# from tensorflow import summary\n",
        "\n",
        "disc = Discriminator(in_channels=3).to(DEVICE)\n",
        "gen = Generator(in_channels=3).to(DEVICE)\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "BCE = nn.BCEWithLogitsLoss()\n",
        "L1_LOSS = nn.L1Loss()\n",
        "\n",
        "disc.train()\n",
        "gen.train()\n",
        "\n",
        "if LOAD_MODEL:\n",
        "  load_checkpoint(CHECKPOINT_GEN_PATH, gen, opt_gen, LEARNING_RATE,)\n",
        "  load_checkpoint(CHECKPOINT_DISC_PATH, disc, opt_disc, LEARNING_RATE,)\n",
        "\n",
        "train_dataset = LoadDataset(root_dir=training_data_folder_path)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True, num_workers=NUM_WORKERS,)\n",
        "\n",
        "validation_dataset = LoadDataset(root_dir=validation_data_folder_path)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False,)\n",
        "\n",
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "curr_epoch = 70\n",
        "residue = 0\n",
        "batchwriter_step = 632*curr_epoch+residue\n",
        "\n",
        "batchwriter = SummaryWriter(runs_path + \"/N2D/batch\", purge_step=batchwriter_step)\n",
        "epochwriter = SummaryWriter(runs_path + \"/N2D/epoch\", purge_step=curr_epoch)\n",
        "\n",
        "\n",
        "for epoch in range(curr_epoch, NUM_EPOCHS):\n",
        "  tr_log = train_fn(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler, batchwriter, batchwriter_step)\n",
        "  #update the tensor board\n",
        "  epochwriter.add_scalar(\"d_real\", float(tr_log[\"d_real\"]), global_step=epoch)\n",
        "  epochwriter.add_scalar(\"d_fake\", float(tr_log[\"d_fake\"]), global_step=epoch)\n",
        "  epochwriter.add_scalar(\"Disc_loss\", float(tr_log[\"Disc_loss\"]), global_step=epoch)\n",
        "  epochwriter.add_scalar(\"Gen_loss\", float(tr_log[\"Gen_loss\"]), global_step=epoch)\n",
        "\n",
        "  if SAVE_MODEL:\n",
        "    save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN_PATH)\n",
        "    save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC_PATH)\n",
        "  val_fn(gen, validation_loader, epoch, saved_imgs_folder=saved_imgs_folder_path, writer=epochwriter)\n",
        "  print(f\"epoch {epoch} is completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0B7CPUYXRHc",
        "outputId": "4f6017e0-9fc6-425e-bbcc-9402f49d73e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 632/632 [15:48<00:00,  1.50s/it, D_fake=0.49, D_real=0.511]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 56 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:19<00:00,  1.17s/it, D_fake=0.489, D_real=0.509]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 57 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:23<00:00,  1.18s/it, D_fake=0.453, D_real=0.483]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 58 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:28<00:00,  1.18s/it, D_fake=0.229, D_real=0.812]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 59 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:32<00:00,  1.19s/it, D_fake=0.326, D_real=0.631]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 60 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:28<00:00,  1.18s/it, D_fake=0.498, D_real=0.495]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 61 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:28<00:00,  1.18s/it, D_fake=0.163, D_real=0.696]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 62 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:36<00:00,  1.20s/it, D_fake=0.275, D_real=0.575]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 63 is completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [12:24<00:00,  1.18s/it, D_fake=0.357, D_real=0.668]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 64 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632/632 [12:28<00:00,  1.18s/it, D_fake=0.47, D_real=0.495]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 65 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632/632 [12:39<00:00,  1.20s/it, D_fake=0.273, D_real=0.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 66 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632/632 [12:34<00:00,  1.19s/it, D_fake=0.465, D_real=0.549]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 67 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632/632 [12:38<00:00,  1.20s/it, D_fake=0.412, D_real=0.444]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 68 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632/632 [12:32<00:00,  1.19s/it, D_fake=0.501, D_real=0.472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 69 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 632/632 [12:26<00:00,  1.18s/it, D_fake=0.496, D_real=0.516]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "epoch 70 is completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 258/632 [05:10<07:52,  1.26s/it, D_fake=0.49, D_real=0.528]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! tensorboard --logdir \"/content/drive/MyDrive/iPURSE/runs\" --port=6006"
      ],
      "metadata": {
        "id": "RQxiBks8x6Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "notebook.display(port=6006, height=1000)"
      ],
      "metadata": {
        "id": "-qA2MOhmH3MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! tensorboard dev upload \\\n",
        "  --logdir \"/content/drive/MyDrive/iPURSE/runs\" \\\n",
        "  --name \"N2D\" \\\n",
        "  --description \"Training\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "id": "693TNCLPIKgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}